# 心理健康AI测评系统

一个综合性的心理健康AI测评系统，用于系统性评估大型语言模型在心理健康领域的各项能力，包括危机识别、伦理推理、谄媚性检测和鲁棒性测试等。

## 📋 目录

- [项目概述](#项目概述)
- [功能特性](#功能特性)
- [系统架构](#系统架构)
- [快速开始](#快速开始)
- [环境配置](#环境配置)
- [使用指南](#使用指南)
- [模块说明](#模块说明)
- [项目结构](#项目结构)
- [技术栈](#技术栈)
- [常见问题](#常见问题)
- [安全说明](#安全说明)
- [许可证](#许可证)

## 🎯 项目概述

本项目是一个完整的心理健康AI测评系统，通过统一的Web界面调用多个独立的测评模块，对大型语言模型在心理健康场景下的能力进行全面评估。

### 核心评估维度

1. **危机识别与升级** - 评估模型识别心理危机并生成适当回复的能力
2. **伦理性测评** - 评估模型在心理健康场景下的伦理推理能力
3. **谄媚性测评** - 检测模型是否存在过度迎合用户观点的倾向
4. **鲁棒性测评** - 测试模型在文本扰动下的表现稳定性

## ✨ 功能特性

- 🌐 **统一Web界面** - 提供友好的Web界面，无需命令行操作
- 🔄 **异步任务执行** - 支持长时间运行的测评任务，实时查看进度
- 📊 **多维度评估** - 涵盖分类、生成、伦理、鲁棒性等多个维度
- 📈 **可视化结果** - 自动生成混淆矩阵、性能对比图等可视化图表
- 🔧 **模块化设计** - 各模块独立运行，易于扩展和维护
- 🛡️ **安全配置** - 使用环境变量管理敏感信息，确保安全性

## 🏗️ 系统架构

### 架构层次

```
┌─────────────────────────────────────┐
│          Web前端界面层                │
│  (HTML/CSS/JavaScript)              │
└──────────────┬──────────────────────┘
               │ HTTP API
┌──────────────▼──────────────────────┐
│         Flask后端服务层              │
│      (app.py - RESTful API)         │
└──────────────┬──────────────────────┘
               │ 模块调用
┌──────────────▼──────────────────────┐
│         测评模块层                   │
│  ┌──────────┬──────────┬─────────┐ │
│  │ 危机识别 │ 伦理性   │ 谄媚性  │ │
│  └──────────┴──────────┴─────────┘ │
│  ┌──────────┬──────────┐          │
│  │ ESConv   │ SWMH     │          │
│  └──────────┴──────────┘          │
└────────────────────────────────────┘
```

### 数据流程

```
用户输入 → Web界面 → Flask API → 测评模块 → LLM API → 结果处理 → 保存输出 → 返回前端
```

## 🚀 快速开始

### 1. 克隆项目

```bash
git clone <repository-url>
cd <project-directory>
```

### 2. 安装依赖

```bash
pip install -r requirements.txt
```

### 3. 配置环境变量

创建 `.env` 文件（参考 `env.example`）：

```bash
# Windows
copy env.example .env

# Linux/Mac
cp env.example .env
```

编辑 `.env` 文件，填入您的API密钥：

```env
OPENAI_API_KEY=your_api_key_here
OPENAI_BASE_URL=https://api.chatanywhere.tech/v1
```

### 4. 设置环境变量（可选）

如果不想使用 `.env` 文件，可以直接设置环境变量：

**Windows (PowerShell):**
```powershell
$env:OPENAI_API_KEY="your_api_key_here"
$env:OPENAI_BASE_URL="https://api.chatanywhere.tech/v1"
```

**Linux/Mac:**
```bash
export OPENAI_API_KEY="your_api_key_here"
export OPENAI_BASE_URL="https://api.chatanywhere.tech/v1"
```

### 5. 启动服务器

```bash
python app.py
```

服务器将在 `http://localhost:5000` 启动。

### 6. 访问Web界面

在浏览器中打开 `http://localhost:5000`，选择要运行的测评模块。

## ⚙️ 环境配置

### 必需环境变量

| 变量名 | 说明 | 示例 |
|--------|------|------|
| `OPENAI_API_KEY` | OpenAI API密钥（必需） | `sk-...` |
| `OPENAI_BASE_URL` | API基础URL（可选） | `https://api.chatanywhere.tech/v1` |

### 使用 python-dotenv（推荐）

安装 `python-dotenv` 后，可以在代码中自动加载 `.env` 文件：

```bash
pip install python-dotenv
```

在代码开头添加：

```python
from dotenv import load_dotenv
load_dotenv()  # 自动加载 .env 文件
```

### 配置验证

运行以下命令验证配置是否正确：

```bash
python -c "import os; print('API Key:', '已设置' if os.getenv('OPENAI_API_KEY') else '未设置')"
```

## 📖 使用指南

### Web界面使用

1. **访问主页**
   - 打开浏览器访问 `http://localhost:5000`
   - 主页显示所有可用的测评模块

2. **选择模块**
   - 点击模块卡片进入对应的测评页面
   - 每个模块有独立的参数配置表单

3. **配置参数**
   - 根据模块要求填写参数
   - 参数说明见各模块说明

4. **执行测评**
   - 点击"开始测评"按钮
   - 任务将在后台执行，页面实时显示状态

5. **查看结果**
   - 任务完成后，结果会显示在页面下方
   - 详细结果保存在各模块的 `outputs/results` 目录

### 命令行使用

各模块也支持命令行直接运行，详见各模块的 `README.md`。

## 📦 模块说明

### 1. 危机识别与升级 (LLMs-Mental-Health-Crisis)

**功能：** 评估模型在心理危机场景下的分类和生成能力

**参数：**
- **任务类型**：`classification`（分类）、`generation`（生成）、`all`（全部）
- **样本数量**：可选，留空使用全部数据

**输出：**
- 分类任务的混淆矩阵和评估指标
- 生成任务的回复质量评分
- JSON格式的详细结果

### 2. 危机识别与升级 (C-SSRS)

**功能：** 评估模型对自杀风险的5级分类能力

**参数：**
- **样本数量**：可选，限制评估样本数

**输出：**
- 5级风险分类的混淆矩阵
- Graded Precision/Recall、Ordinal Error等特殊指标
- 详细的评估报告

### 3. 伦理性测评

**功能：** 评估模型在心理健康场景下的伦理推理能力

**参数：**
- **样本数量**：默认10，可自定义

**输出：**
- 伦理推理评估结果
- 模型决策的伦理分析

### 4. 谄媚性测评

**功能：** 评估模型是否存在过度迎合用户观点的倾向

**参数：**
- **数据集**：`OEQ`、`AITA-YTA`、`PAS`
- **样本数量**：可选，限制评估样本数

**输出：**
- 谄媚性评分统计
- 各数据集的评估结果汇总

### 5. 鲁棒性测评 (ESConv)

**功能：** 评估模型在文本扰动下的分类稳定性

**参数：**
- **样本数量**：可选
- **扰动类型**：`none`、`char`、`word`、`sentence`、`all`
- **随机种子**：可选，用于可重复实验

**输出：**
- 不同扰动强度下的性能对比
- 鲁棒性分析报告

### 6. 鲁棒性测评 (SWMH)

**功能：** 评估模型在心理健康文本分类中的鲁棒性

**参数：**
- **样本数量**：可选
- **扰动类型**：`none`、`char`、`word`、`sentence`、`all`
- **随机种子**：可选

**输出：**
- 分类性能在不同扰动下的变化
- 鲁棒性评估报告

## 📁 项目结构

```
项目根目录/
├── app.py                          # Flask后端服务器
├── index.html                       # 主页面
├── interface.html                   # 统一Web界面
├── styles.css                       # 样式文件
├── common.js                        # 通用JavaScript函数
├── requirements.txt                 # Python依赖
├── README.md                        # 项目说明文档
├── env.example                      # 环境变量示例文件
├── .gitignore                       # Git忽略文件配置
│
├── 危机识别与升级/
│   ├── LLMs-Mental-Health-Crisis/   # LLMs危机识别模块
│   │   ├── main.py
│   │   ├── src/                     # 源代码目录
│   │   ├── data/                    # 数据集目录
│   │   └── outputs/                 # 输出目录
│   └── C-SSRS/                      # C-SSRS风险评估模块
│       ├── main.py
│       ├── src/
│       ├── data/
│       └── outputs/
│
├── 伦理性/                          # 伦理推理测评模块
│   ├── main.py
│   ├── src/
│   ├── data/
│   └── outputs/
│
├── 谄媚性/                          # 谄媚性测评模块
│   ├── main.py
│   ├── src/
│   ├── data/
│   └── outputs/
│
└── 鲁棒性/
    ├── ESConv/                      # ESConv分类与鲁棒性评估
    │   ├── main.py
    │   ├── src/
    │   ├── data/
    │   └── outputs/
    └── SWMH/                         # SWMH分类与鲁棒性评估
        ├── main.py
        ├── src/
        ├── data/
        └── outputs/
```

### 标准模块结构

每个测评模块遵循统一的结构：

```
模块目录/
├── main.py              # 主入口文件
├── src/                 # 源代码目录
│   ├── settings.py      # 配置（API密钥、模型等）
│   ├── data_utils.py    # 数据处理工具
│   ├── classification.py # 分类任务（如适用）
│   ├── generation.py     # 生成任务（如适用）
│   ├── prompts.py        # 提示词模板
│   └── ...              # 其他功能模块
├── data/                # 数据集目录
├── outputs/             # 输出目录
│   ├── results/         # 结果文件
│   └── logs/            # 日志文件
└── README.md            # 模块说明文档
```

## 🛠️ 技术栈

### 后端技术
- **Web框架**：Flask 3.0.0
- **跨域支持**：Flask-CORS 4.0.0
- **API客户端**：OpenAI SDK
- **数据处理**：pandas, numpy
- **评估指标**：scikit-learn
- **可视化**：matplotlib

### 前端技术
- **HTML/CSS/JavaScript**：原生实现，无框架依赖
- **AJAX**：异步请求处理
- **DOM操作**：动态界面更新

### 数据格式
- **输入格式**：JSON, JSONL, CSV
- **输出格式**：JSON（详细结果）、TXT（文本摘要）、PNG（可视化图像）

## ❓ 常见问题

### Q1: 如何配置API密钥？

A: 有两种方式：
1. 创建 `.env` 文件，参考 `env.example`
2. 直接设置环境变量 `OPENAI_API_KEY`

详见 [环境配置](#环境配置) 章节。

### Q2: 任务执行时间很长怎么办？

A: 
- 首次测试建议使用小样本（如10个）
- 任务在后台执行，可以关闭浏览器，稍后查看结果
- 结果保存在 `outputs/results` 目录中

### Q3: 如何查看详细结果？

A: 
- Web界面显示任务输出摘要
- 详细结果保存在各模块的 `outputs/results` 目录
- 结果包含JSON格式的详细数据和可视化图表

### Q4: 可以同时运行多个任务吗？

A: 可以，但建议一次运行一个任务，避免资源冲突和API限流。

### Q5: 如何修改模型配置？

A: 编辑各模块的 `src/settings.py` 文件，修改模型名称等配置。

### Q6: 输出文件在哪里？

A: 所有输出文件保存在各模块的 `outputs/` 目录下：
- `outputs/results/` - 结果文件（JSON、TXT）
- `outputs/logs/` - 日志文件

### Q7: 如何清理输出文件？

A: 输出文件已被 `.gitignore` 排除，不会提交到Git。如需清理本地文件：

```bash
# 删除所有输出目录
find . -type d -name "outputs" -exec rm -rf {} +
```

## 🔒 安全说明

### API密钥安全

- ✅ 所有API密钥通过环境变量配置，不硬编码在代码中
- ✅ `.env` 文件已被 `.gitignore` 排除，不会提交到Git
- ✅ 输出文件中的敏感信息已被排除

### 安全建议

1. **不要提交敏感文件**
   - `.env` 文件
   - 包含API密钥的文件
   - 输出文件和日志文件

2. **定期轮换密钥**
   - 如果怀疑密钥泄露，立即更换
   - 定期检查API使用情况

3. **使用密钥管理服务**
   - 考虑使用专业的密钥管理服务
   - 避免在代码和配置文件中存储密钥

### 如果之前已提交过敏感信息

如果之前已经将包含敏感信息的文件提交到Git仓库，需要清理历史：

```bash
# 使用git filter-branch清理历史
git filter-branch --force --index-filter \
  "git rm --cached --ignore-unmatch -r outputs/" \
  --prune-empty --tag-name-filter cat -- --all
```

## 📝 开发说明

### 添加新模块

1. 在项目根目录创建新模块目录
2. 遵循标准模块结构（参考 [项目结构](#项目结构)）
3. 在 `app.py` 中添加模块路由和处理函数
4. 创建对应的HTML页面

### 代码规范

- 使用中文注释和文档字符串
- 遵循PEP 8代码风格
- 模块化设计，高内聚低耦合

### 测试建议

- 使用小样本进行功能测试
- 检查输出格式和内容
- 验证评估指标计算的正确性

## 📄 许可证

本项目仅供学习和研究使用。

## 🤝 贡献

欢迎提交Issue和Pull Request！

## 📧 联系方式

如有问题或建议，请通过Issue联系。

---

**祝使用愉快！** 🎉

